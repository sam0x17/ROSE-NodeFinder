In June 2012, we rewrote the memory state class for SymbolicSemantics
with a new version with the following differences:

1. Memory reads are symbolic.  A memory read returns a McCarthy
   expression (a big if-then-else selecting on the address used when
   reading) and hands it to the SMT solver. The old behavior was to
   return the value of a single "best" memory cell.

2. Memory cells contain only eight-bit values.  A multi-byte write
   splits the value into individual 1-byte cells, and a multi-byte
   read concatenates multiple cells.  The old behavior was that a cell
   could contain 8, 16, or 32 bits (which would have been extended to
   include 64, 80, and 128 bits when we implemented the 64-bit and
   floating point x86 instructions).


Benefits for Symbolic memory reads:

a. Pushing the entire memory state to the SMT solver means that the
   SMT solver will have more to work with and give more accurate
   results.

   Example: Assume we have a memory state with two cells, each having
   an address and a value: { (A1,V1), (A2,V2) }.  A read from address
   A3 in the new implementation returns the expression:

      (if A3 == A1 then V1 else if A3 == A2 then V2)

   The old implementation scanned the cell list and returned either V1
   or V2 depending on whether A3==A1 or A3==A2, or it returned a new
   value V3 unrelated to any other when A3 didn't match any cell or
   matched multiple cells.  The old implementation caused information
   to be lost when calling the SMT solver.

Benefits for single-byte cell values:

a. The old implementation had variable sized memory cells, the size of
   the cell depending on the size of the memory-write operation that
   created the cell.  We had cells that were 8, 16, and 32 bits would
   have eventually implemented 64, 80, and 128.  The new
   implementation simplifies this by allowing only 8-bit cells.

b. The equations for determining whether two cells are aliases are
   simpler in the new implementation: two cells are aliases if their
   addresses are equal.

c. With the new implementation, we don't need any complicated logic
   for figuring out what to do when a read or write partially aliases
   existing cells.  E.g., two 32-bit writes at address 0 and 4
   followed by a 32-bit read at address 2.  We were encountering code
   that actually did things like this.

d. Storing only 1-byte cells doesn't actually preclude us from also
   storing the size of the write that produced the cells--just that we
   don't currently do that.

e. We won't have to do anything special for memory in order to support
   64-bit specimens, especially when a specimen mixes 32- and
   64-bit memory accesses.  Similarly for adding floating point and
   SIMD instructions, some of which we are already supporting in other
   projects.

h. Real x86 memory is byte addressable, so the new implementation more
   closely matches real hardware.


Drawbacks:

a. Symbolic reads mean more complex expressions are handed to the SMT
   solver, making the SMT solver calls more expensive.  This is the
   price we pay for accuracy.  However, we found that instead of
   handing the entire memory state to the SMT solver for a memory read
   operation, we can first use the SMT solver to prune the cell list
   and and then produce a smaller McCarthy expression; this is more,
   but smaller calls to the SMT solver and (at least for Yices) is
   about 3x faster IIRC.

b. A memory read results in a more complex expression when all you're
   trying to do is obtain a memory value (not necessarily passing it
   to an SMT solver).  Again, this is the price of accuracy.

c. Single-byte cells don't store information about the size and
   starting address of the write operation that produced the cells.
   It would be easy to add this information back into the cell list if
   needed.  We could even redundantly store the original multi-byte
   value passed to the memory-write operation.  We've kicked around
   the idea a couple times and always come to the conclusion that it
   isn't necessary.

d. An initial drawback was that if you wrote 32-bit value V1 to memory
   address A1 and then read a 32-bit value from A1 you'd end up with a
   symbolic expression that was a concatenation of four extractions, a
   significantly more complex expression than just V1.  However, we've
   added code to simplify these expressions: writing and then reading
   from the same address should give you the same expression that was
   originally written.  We plan to add additional simplifications in a
   more general way.








commit 7abc72c3983f907e8385118237db695582430458
Author: Robb Matzke <matzke1@llnl.gov>
Date:   Fri Jun 29 15:57:05 2012 -0400

    (Binary Analysis) New symbolic memory layer
    
    Originally we had a simple memory lookup table consisting of a
    MemoryCell list and we resolved a memory read operation at the time
    of the read.  Then we replace it with a purely symbolic method and
    discovered that it was much too expensive (60 seconds to simulate
    the first 100 instructions of ld-linux.so).
    
    This change introduces a new memory representation that's a
    combination of the lookup table and delayed (McCarthy-style)
    evaluation.
    
    This commit also changes SymbolicSemantics so that its memory
    is byte addressable.  All multi-byte access is via one byte
    at a time in order to more accurately model non-aligned writes
    with potential aliasing.
    
    This is the initial checkin, not fully tested.  All symbolic
    semantics layers changed, but the main behavioral changes are
    only in SymbolicSemantics, especially when using an SMT solver.
